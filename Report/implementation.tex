The algorithms are implemented in C++ version 14 and use BuDDy\footnote{\label{note1}https://sourceforge.net/projects/buddy/} \cite{buddy} as a BDD library. The complete source is hosted on github\footnote{\label{note2}https://github.com/SjefvanLoo/VariabilityParityGames/tree/master/implementation/VPGSolver}.

The implementation is split in three phases: parsing, solving and solution printing. The solving part contains the implementations of the algorithms presented. The parsing and solution printing parts are implemented trivially and hardly optimized and their running times are not considered in the experimental evaluation.

The parsing phase of the algorithm creates BDDs from the input file and in doing so parts of the BDD cache gets filled. After parsing the BDD cache is cleared to make sure that the work done in the solving phase corresponds with the algorithms presented and no work to assist it has been done prior to this phase. Creating BDDs is not a trivial task, however one could argue that an FTS should already express its transition guards as BDDs. In any case, we leave the creation of BDDs out of scope.

\subsection{Game representation}
The graph is represented using adjacency lists for incoming and outgoing edges, furthermore every edge maps to a set of configurations representing the $\theta$ value for the edge. Sets of configurations are either represented symbolically or explicitly. In the former case we use BDDs, in the latter case we use bit-vectors. For independent algorithms the edges are not mapped to sets of configurations. Finally sets of vertices are represented using bit-vectors.

Note that only the representation of the games used during the algorithm is relevant. Since we do not evaluate the parsing phase it is not relevant how the games are stored in a file.
\subsection{Independent algorithms}
Four independent algorithms are implemented, i.e. standard parity game algorithms. A global and local variant is implemented of the following algorithms:
\begin{itemize}
	\item Zielonka's recursive algorithm and
	\item fixed-point iteration algorithm.
\end{itemize}
We implement the fixed-point iteration algorithm to use pre-solved vertices $P_0$ and $P_1$. When using the algorithm for an independent approach we use $\emptyset$ for $P_0$ and $P_1$, in which case the algorithm behaves the same as the original fixed-point iteration algorithm.

A few optimizations are applied to the fixed-point iteration algorithm. The following three are described in \cite{FPITE}:
\begin{itemize}
	\item For fixed-point variable $Z_i$ its value is only ever used to check if a vertex with priority $i$ is in $Z_i$. So instead of storing all vertices in $Z_i$ we only have to store the vertices that have priority $i$. We can store all fixed-point variables in a single bit-vector, named $Z$, of size $n$.
	\item The algorithm only updates a certain range of fixed-point variables. So the diamond and box operations can use the previous result and only reconsider vertices that have an edge to a vertex that has a priority for which its fixed-point variable is updated.
	\item The algorithm updates variables $Z_0$ to $Z_m$ and reinitializes $Z_0$ to $Z_{m-1}$, however if $Z_m$ is a least fixed-point variable then $Z_m$ has just increased and due to monotonicity the other least fixed-point formulas, i.e. $Z_{m-2},Z_{m-4},\dots$, will also increase so there is no need to reset them. Similarly for greatest fixed-point variables. So we only to reset half of the variables instead of all of them.
\end{itemize}
Furthermore, the vertices in the game are reordered such that they are sorted by parity first and by priority second. Using the above optimizations the algorithm needs to reset variables $Z_{m}, Z_{m-2},\dots$. These variables are stored in a single bit-vector $Z$. By reordering the variables to be sorted by parity and priority these vertices that need to be reset are always consecutively stored in $Z$. Resetting this sequence can be done by a memory copy instead of iterating all the different vertices. Note that when the algorithm is used by the pre-solve algorithm the variables are not reset to simply $\emptyset$ and $V$ but are reset to two specific bit-vectors that are given by the pre-solve algorithm. These bit-vectors have the same order and resetting can be done by copying a part of them into $Z$.

The advantage of using a memory copy as opposed to iterating all the different vertices is due to the fact that a bit vector uses integers to store its boolean values. A 64-bit integer can store 64 boolean values. Iterating and writing every boolean value individually causes the integer to be written 64 times. However with a memory copy we can simply copy the entire integer value and the integer is only written once.

Finally, priority compression is applied when using the fixed-point iteration algorithm. Priority compression makes sure the lowest priority is 0 or 1 and for every priority $p$ that is lower or equal to the highest priority occurring in the game we have $p$ being either the lowest priority in the game or there is a vertex in the game with priority $p-1$ \cite{FPITE,friedmanPG}.

\subsection{Collective algorithms}
Six collective algorithms are implemented, i.e. algorithms for solving VPGs. A global and local variant is implemented of the following algorithms:
\begin{itemize}
	\item Zielonka's recursive algorithm for VPGs with explicit configuration set representation,
	\item Zielonka's recursive algorithm for VPGs with symbolic configuration set representation and
	\item incremental pre-solve algorithm.
\end{itemize}
The incremental pre-solve algorithms uses the fixed-point iteration algorithm as described above to solve the (pessimistic) parity games. When using the incremental pre-solve algorithm we apply priority compression once, directly on the VPG. Since the (pessimistic) parity games that are created during the algorithm have the same vertices as the VPG we do not have to apply priority compression again when using the fixed-point iteration algorithm to solve them.

The incremental pre-solve algorithm creates subgames by splitting the set of configurations. The games we evaluate are based on features so we simply split the set of configurations by arbitrarily choosing a feature and including this feature in one set of configurations and excluding this feature in the other set of configurations. The problem of finding good heuristics to split the sets of configurations is also described in \cite{FamBasedModelCheckingWithMCRL2}. We leave this problem out of scope for this research.
\subsection{Random verification}
In order to prevent implementation mistakes 200 VPGs are created randomly, every VPG is projected to all its configurations to get a set of parity games. These parity games are solved using the PGSolver tool \cite{Friedmann2010ThePC}. All algorithms implemented are used to solve the 200 VPGs independently and collectively, the solutions are verified against the solutions created by the PGSolver.